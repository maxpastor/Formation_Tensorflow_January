{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Training step:', '0000', 'cost=', '2.371479273', 'Precision=', '0.135600001')\n",
      "('Training step:', '1000', 'cost=', '1.681881785', 'Precision=', '0.665099978')\n",
      "('Training step:', '2000', 'cost=', '1.095653176', 'Precision=', '0.785700023')\n",
      "('Training step:', '3000', 'cost=', '0.776192665', 'Precision=', '0.835399985')\n",
      "('Training step:', '4000', 'cost=', '0.647628009', 'Precision=', '0.860499978')\n",
      "('Training step:', '5000', 'cost=', '0.566192746', 'Precision=', '0.874499977')\n",
      "('Training step:', '6000', 'cost=', '0.537851393', 'Precision=', '0.882300019')\n",
      "('Training step:', '7000', 'cost=', '0.447130919', 'Precision=', '0.889100015')\n",
      "('Training step:', '8000', 'cost=', '0.411988258', 'Precision=', '0.894200027')\n",
      "('Training step:', '9000', 'cost=', '0.431324005', 'Precision=', '0.898000002')\n",
      "('Training step:', '10000', 'cost=', '0.429902285', 'Precision=', '0.899399996')\n",
      "('Training step:', '11000', 'cost=', '0.350362509', 'Precision=', '0.902000010')\n",
      "('Training step:', '12000', 'cost=', '0.382137448', 'Precision=', '0.903999984')\n",
      "('Training step:', '13000', 'cost=', '0.356538683', 'Precision=', '0.906099975')\n",
      "('Training step:', '14000', 'cost=', '0.371291161', 'Precision=', '0.907999992')\n",
      "('Training step:', '15000', 'cost=', '0.321167409', 'Precision=', '0.909600019')\n",
      "('Training step:', '16000', 'cost=', '0.288808852', 'Precision=', '0.911300004')\n",
      "('Training step:', '17000', 'cost=', '0.322981477', 'Precision=', '0.913100004')\n",
      "('Training step:', '18000', 'cost=', '0.334515303', 'Precision=', '0.914600015')\n",
      "('Training step:', '19000', 'cost=', '0.323536575', 'Precision=', '0.916100025')\n",
      "('Training step:', '20000', 'cost=', '0.314355463', 'Precision=', '0.917999983')\n",
      "('Training step:', '21000', 'cost=', '0.302470565', 'Precision=', '0.918900013')\n",
      "('Training step:', '22000', 'cost=', '0.273178786', 'Precision=', '0.920000017')\n",
      "('Training step:', '23000', 'cost=', '0.270047843', 'Precision=', '0.921100020')\n",
      "('Training step:', '24000', 'cost=', '0.274719059', 'Precision=', '0.922100008')\n",
      "('Training step:', '25000', 'cost=', '0.257514268', 'Precision=', '0.923399985')\n",
      "('Training step:', '26000', 'cost=', '0.286986321', 'Precision=', '0.924300015')\n",
      "('Training step:', '27000', 'cost=', '0.283488899', 'Precision=', '0.924899995')\n",
      "('Training step:', '28000', 'cost=', '0.306584060', 'Precision=', '0.925400019')\n",
      "('Training step:', '29000', 'cost=', '0.294999927', 'Precision=', '0.926699996')\n",
      "('Training step:', '30000', 'cost=', '0.295498550', 'Precision=', '0.927500010')\n",
      "('Training step:', '31000', 'cost=', '0.220339924', 'Precision=', '0.927900016')\n",
      "('Training step:', '32000', 'cost=', '0.291785896', 'Precision=', '0.928499997')\n",
      "('Training step:', '33000', 'cost=', '0.249483392', 'Precision=', '0.929799974')\n",
      "('Training step:', '34000', 'cost=', '0.269062728', 'Precision=', '0.930599988')\n",
      "('Training step:', '35000', 'cost=', '0.279092580', 'Precision=', '0.931200027')\n",
      "('Training step:', '36000', 'cost=', '0.249709666', 'Precision=', '0.931999981')\n",
      "('Training step:', '37000', 'cost=', '0.195342302', 'Precision=', '0.932500005')\n",
      "('Training step:', '38000', 'cost=', '0.232642084', 'Precision=', '0.933300018')\n",
      "('Training step:', '39000', 'cost=', '0.277144521', 'Precision=', '0.933600008')\n",
      "('Training step:', '40000', 'cost=', '0.235829264', 'Precision=', '0.934300005')\n",
      "('Training step:', '41000', 'cost=', '0.223239228', 'Precision=', '0.935000002')\n",
      "('Training step:', '42000', 'cost=', '0.227636680', 'Precision=', '0.935299993')\n",
      "('Training step:', '43000', 'cost=', '0.217058137', 'Precision=', '0.935699999')\n",
      "('Training step:', '44000', 'cost=', '0.228355750', 'Precision=', '0.936200023')\n",
      "('Training step:', '45000', 'cost=', '0.211681634', 'Precision=', '0.936600029')\n",
      "('Training step:', '46000', 'cost=', '0.252723396', 'Precision=', '0.937399983')\n",
      "('Training step:', '47000', 'cost=', '0.233334959', 'Precision=', '0.937900007')\n",
      "('Training step:', '48000', 'cost=', '0.233957335', 'Precision=', '0.938499987')\n",
      "('Training step:', '49000', 'cost=', '0.203593984', 'Precision=', '0.938799977')\n",
      "('Training step:', '50000', 'cost=', '0.199235782', 'Precision=', '0.939100027')\n",
      "('Training step:', '51000', 'cost=', '0.208567828', 'Precision=', '0.939400017')\n",
      "('Training step:', '52000', 'cost=', '0.215270445', 'Precision=', '0.939599991')\n",
      "('Training step:', '53000', 'cost=', '0.199582621', 'Precision=', '0.939800024')\n",
      "('Training step:', '54000', 'cost=', '0.214594275', 'Precision=', '0.940299988')\n",
      "('Training step:', '55000', 'cost=', '0.204896510', 'Precision=', '0.940800011')\n",
      "('Training step:', '56000', 'cost=', '0.222823098', 'Precision=', '0.940900028')\n",
      "('Training step:', '57000', 'cost=', '0.203251868', 'Precision=', '0.941500008')\n",
      "('Training step:', '58000', 'cost=', '0.187089294', 'Precision=', '0.941900015')\n",
      "('Training step:', '59000', 'cost=', '0.222071990', 'Precision=', '0.942399979')\n",
      "('Training step:', '60000', 'cost=', '0.215097412', 'Precision=', '0.943000019')\n",
      "('Training step:', '61000', 'cost=', '0.249321654', 'Precision=', '0.943400025')\n",
      "('Training step:', '62000', 'cost=', '0.196004912', 'Precision=', '0.943700016')\n",
      "('Training step:', '63000', 'cost=', '0.211432636', 'Precision=', '0.944400012')\n",
      "('Training step:', '64000', 'cost=', '0.198548451', 'Precision=', '0.944299996')\n",
      "('Training step:', '65000', 'cost=', '0.196464524', 'Precision=', '0.944800019')\n",
      "('Training step:', '66000', 'cost=', '0.227841586', 'Precision=', '0.945599973')\n",
      "('Training step:', '67000', 'cost=', '0.202016696', 'Precision=', '0.945900023')\n",
      "('Training step:', '68000', 'cost=', '0.197357655', 'Precision=', '0.945900023')\n",
      "('Training step:', '69000', 'cost=', '0.189689115', 'Precision=', '0.945999980')\n",
      "('Training step:', '70000', 'cost=', '0.180925265', 'Precision=', '0.946500003')\n",
      "('Training step:', '71000', 'cost=', '0.155823901', 'Precision=', '0.947000027')\n",
      "('Training step:', '72000', 'cost=', '0.172905773', 'Precision=', '0.947200000')\n",
      "('Training step:', '73000', 'cost=', '0.164851680', 'Precision=', '0.947300017')\n",
      "('Training step:', '74000', 'cost=', '0.184479952', 'Precision=', '0.947600007')\n",
      "('Training step:', '75000', 'cost=', '0.175236389', 'Precision=', '0.948000014')\n",
      "('Training step:', '76000', 'cost=', '0.167245582', 'Precision=', '0.948099971')\n",
      "('Training step:', '77000', 'cost=', '0.170863137', 'Precision=', '0.948300004')\n",
      "('Training step:', '78000', 'cost=', '0.206846163', 'Precision=', '0.948599994')\n",
      "('Training step:', '79000', 'cost=', '0.174765214', 'Precision=', '0.948700011')\n",
      "('Training step:', '80000', 'cost=', '0.169833258', 'Precision=', '0.949400008')\n",
      "('Training step:', '81000', 'cost=', '0.163706407', 'Precision=', '0.950399995')\n",
      "('Training step:', '82000', 'cost=', '0.171908721', 'Precision=', '0.950999975')\n",
      "('Training step:', '83000', 'cost=', '0.171567827', 'Precision=', '0.951300025')\n",
      "('Training step:', '84000', 'cost=', '0.212651372', 'Precision=', '0.951399982')\n",
      "('Training step:', '85000', 'cost=', '0.164718926', 'Precision=', '0.951600015')\n",
      "('Training step:', '86000', 'cost=', '0.163528204', 'Precision=', '0.951900005')\n",
      "('Training step:', '87000', 'cost=', '0.131880611', 'Precision=', '0.952000022')\n",
      "('Training step:', '88000', 'cost=', '0.160310790', 'Precision=', '0.952099979')\n",
      "('Training step:', '89000', 'cost=', '0.143365234', 'Precision=', '0.952499986')\n",
      "('Training step:', '90000', 'cost=', '0.144142166', 'Precision=', '0.952700019')\n",
      "('Training step:', '91000', 'cost=', '0.176752657', 'Precision=', '0.953199983')\n",
      "('Training step:', '92000', 'cost=', '0.150200188', 'Precision=', '0.953499973')\n",
      "('Training step:', '93000', 'cost=', '0.166434214', 'Precision=', '0.953599989')\n",
      "('Training step:', '94000', 'cost=', '0.153476790', 'Precision=', '0.953899980')\n",
      "('Training step:', '95000', 'cost=', '0.135384396', 'Precision=', '0.954599977')\n",
      "('Training step:', '96000', 'cost=', '0.167287111', 'Precision=', '0.954699993')\n",
      "('Training step:', '97000', 'cost=', '0.165830687', 'Precision=', '0.954999983')\n",
      "('Training step:', '98000', 'cost=', '0.106605895', 'Precision=', '0.955100000')\n",
      "('Training step:', '99000', 'cost=', '0.139263079', 'Precision=', '0.955100000')\n",
      "0.9553\n",
      "Optimization Finished!\n",
      "('Model Saved -> ', './models/mnist_classifier.ckpt')\n"
     ]
    }
   ],
   "source": [
    "#paramètres\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100000\n",
    "display_step = 1000\n",
    "#n_samples = inputY.size\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#Définition des neuronnes et des layers\n",
    "n_neurons_1 = 256\n",
    "n_neurons_2 = 128\n",
    "\n",
    "\n",
    "#Definition des variables\n",
    "with tf.device('/device:GPU:0'):\n",
    "    weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=1)\n",
    "    bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "    W_hidden_1 = tf.Variable(weight_initializer([784, n_neurons_1]))\n",
    "    bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "\n",
    "    W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "    bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    W_out = tf.Variable(weight_initializer([n_neurons_2, 10]))\n",
    "    bias_out = tf.Variable(bias_initializer([10]))\n",
    "\n",
    "    #Définition du graph\n",
    "\n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "    \n",
    "\n",
    "    out = tf.nn.softmax(tf.add(tf.matmul(hidden_2, W_out), bias_out))\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(out), reduction_indices=[1])) #cross entropy\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "for i in range(training_epochs):  \n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(opt, feed_dict={X: batch_xs, Y:batch_ys}) # Take a gradient descent step using our inputs and labels\n",
    "\n",
    "    # That's all! The rest of the cell just outputs debug messages. \n",
    "    # Display logs per epoch step\n",
    "    if (i) % display_step == 0:\n",
    "        #summary_str = cost_summary.eval(feed_dict={X: inputX, Y:inputY}, session= sess)\n",
    "        cc = sess.run(cost, feed_dict={X: batch_xs, Y:batch_ys})\n",
    "        #file_writer.add_summary(summary_str, i)\n",
    "        precision = sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                     Y: mnist.test.labels})\n",
    "        print(\"Training step:\", '%04d' % (i), \"cost=\", \"{:.9f}\".format(cc), \"Precision=\", \"{:.9f}\".format(precision)) #, \\\"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "#file_writer.close()\n",
    "save_path =  saver.save(sess, \"./models/mnist_classifier.ckpt\")\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                     Y: mnist.test.labels}))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Model Saved -> \", save_path)\n",
    "training_cost = sess.run(cost, feed_dict={X: batch_xs, Y: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
